{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473521a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/anaconda3/envs/ome_zarr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ad881",
   "metadata": {},
   "source": [
    "# A differentiable version of an auto-repression bursting model\n",
    "\n",
    "$G \\to G'$ with rate $k_{on}$\n",
    "\n",
    "$G' + P \\to G + P$ with rate $k_{off}$\n",
    "\n",
    "$0 \\to M$ with rate $r_m$\n",
    "\n",
    "$M \\to M + P$ with rate $r_p$\n",
    "\n",
    "$M \\to 0$ with rate $\\gamma_m$\n",
    "\n",
    "$P \\to 0$ with rate $\\gamma_p$\n",
    "\n",
    "Note: we are following Krishna's paper where OFF corresponds to $G=-1$. This is useful for smoothing with a sigmoid, such that $\\sigma(-1) \\to 0$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592c1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stoichiometry matrix for the reactions\n",
    "stoic_matrix = torch.tensor([[2.0, 0.0, 0.0],    # Reaction 1: Promoter state goes from -1 to +1\n",
    "                             [-2.0, 0.0, 0.0],   # Reaction 2: Promoter state goes from 1 to -1\n",
    "                             [0.0, 1.0, 0.0],    # Reaction 3: mRNA production\n",
    "                             [0.0, 0.0, 1.0],    # Reaction 4: protein production\n",
    "                             [0.0, -1.0, 0.0],   # Reaction 5: Degradation of mRNA\n",
    "                             [0.0, 0.0, -1.0]])  # Reaction 6: protein degradation\n",
    "\n",
    "# Define a function to compute the state jump\n",
    "def state_jump(reaction_index, stoic_matrix):\n",
    "    \"\"\"\n",
    "    Calculate state jump vector based on the selected reaction index and stoichiometry matrix, where, \n",
    "    state vector -> state vector + state jump vector.\n",
    "\n",
    "    Arguments:\n",
    "        reaction_index: Selected reaction index\n",
    "        stoic_matrix: Stoichiometry matrix\n",
    "\n",
    "    Returns:\n",
    "        State jump vector\n",
    "    \"\"\"\n",
    "    return torch.sum(stoic_matrix * (torch.exp(-b_inv* (reaction_index - torch.arange(stoic_matrix.shape[0]))**2)).view(-1, 1), dim=0)\n",
    "\n",
    "# Define a function to select the reaction based on reaction selection thresholds\n",
    "def reaction_selection(breaks, random_num):\n",
    "    \"\"\"\n",
    "    Select reaction based on the transition points and a random number. Transition points are \n",
    "    given by the ratio of cumulative sum of rates and the total rate.\n",
    "    \n",
    "    Arguments:\n",
    "        breaks: Transition points between [0,1]\n",
    "        random_num: Random number in [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Index of the next reaction\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.sigmoid(a_inv * (random_num - breaks)))\n",
    "\n",
    "# Define the Gillespie simulation function\n",
    "def gillespie_simulation(r_m, r_p, k_on, k_off, num_simulations, sim_time, a_inv, b_inv, c):\n",
    "    \"\"\"\n",
    "    Perform differentiable Gillespie simulation for a 2-state promoter model.\n",
    "    \n",
    "    Arguments:\n",
    "        r_m: Rate of mRNA production.\n",
    "        r_p: Rate of protein production\n",
    "        k_on: Rate of promoter switching from -1 to +1.\n",
    "        k_off: Rate of promoter switching from 1 to -1 (not including protein level).\n",
    "        num_simulations: Number of simulations to run.\n",
    "        sim_time: Simulation time.\n",
    "        a_inv: Inverse parameter for reaction selection.\n",
    "        b_inv : Inverse parameter for state jump calculation.\n",
    "        c: Sigmoid slope parameter for propensities.\n",
    "        \n",
    "    Returns:\n",
    "        mean_final_state: Mean of the mRNA levels at the end of the simulation.\n",
    "        variance: Variance of the mRNA levels at the end of the simulation.\n",
    "    \"\"\"\n",
    "    # Initialize random seed for reproducibility\n",
    "    random_seed = torch.randint(1, 10000000, (1,))\n",
    "    #print (random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    final_states = 0.0\n",
    "    final_states_squared = 0.0\n",
    "\n",
    "    # Main simulation loop\n",
    "    for j in range(num_simulations):\n",
    "        # Initialize 'levels':\n",
    "        # The first component of 'levels' is the promoter state, initialized to 0\n",
    "        # The second component of 'levels' is the mRNA count, initailized to 0.\n",
    "        levels = torch.stack([torch.tensor(-1.0), torch.tensor(0.0), torch.tensor(0.0)])\n",
    "        current_time = 0.0\n",
    "\n",
    "        # Main simulation loop\n",
    "        while current_time < sim_time:\n",
    "            # Calculate reaction propensities\n",
    "            propensities = torch.stack([k_on*torch.sigmoid(-c*levels[0]),            # Rate of promoter state switching from -1 to +1\n",
    "                                        k_off*levels[2]*torch.sigmoid(c*levels[0]),  # Rate of promoter state switching from +1 to -1\n",
    "                                        r_m*torch.sigmoid(-c*levels[0]),             # Rate of mRNA production\n",
    "                                        r_p*levels[1],                               # Rate of mRNA production\n",
    "                                        gamma_m*levels[1],                           # Rate of mRNA degradation\n",
    "                                        gamma_p*levels[2]])                          # Rate of protein degradation             \n",
    "\n",
    "            # Calculate total propensity\n",
    "            total_propensity = propensities.sum()\n",
    "\n",
    "            # Generate a random number to determine time to next reaction\n",
    "            dt = -torch.log(torch.rand(1)) / total_propensity\n",
    "            current_time += dt.item()\n",
    "\n",
    "            # Check if the simulation exceeds sim_time. If it exceeds, quit the simulation.\n",
    "            if current_time >= sim_time:\n",
    "                break\n",
    "\n",
    "            # Update state vector\n",
    "            breaks = (propensities[:-1] / total_propensity).cumsum(dim=0)\n",
    "            reaction_index = reaction_selection(breaks, torch.rand(1))\n",
    "            levels = levels + state_jump(reaction_index, stoic_matrix)\n",
    "            levels[1] = torch.relu(levels[1]) \n",
    "\n",
    "        # Accumulate final states after each sumulation\n",
    "        final_states += levels[1]\n",
    "        final_states_squared += levels[1] ** 2\n",
    "\n",
    "    # Calculate mean and variance of mRNA levels (from the accumulated final states)\n",
    "    mean_final_state = final_states / num_simulations\n",
    "    variance = final_states_squared / num_simulations - mean_final_state ** 2\n",
    "\n",
    "    # Return mean mRNA level and variance\n",
    "    return mean_final_state, variance\n",
    "\n",
    "# Define the loss function \n",
    "def loss_function(mean_final_state, variance, target_mean, target_std):\n",
    "    \"\"\"\n",
    "    Calculates the mean squared error of the simulation results against data\n",
    "    \"\"\"\n",
    "    return (mean_final_state - target_mean) ** 2 + (variance ** 0.5 - target_std) ** 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4636e",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7fae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_m = 1.0\n",
    "r_p = 1.0\n",
    "k_on = 0.05\n",
    "k_off = 0.10\n",
    "gamma_m = 0.23\n",
    "gamma_p = 0.23\n",
    "\n",
    "# Hyperparameters\n",
    "num_simulations=50\n",
    "a_inv=200.0\n",
    "b_inv=20.0\n",
    "c=20.0\n",
    "sim_time=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f7cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1439364])\n"
     ]
    }
   ],
   "source": [
    "mean_final_state, variance =  gillespie_simulation(r_m, r_p, k_on, k_off, num_simulations, sim_time, a_inv, b_inv, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6bb5cc",
   "metadata": {},
   "source": [
    "## Try out fitting simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59eba680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"generate ground truth\"\"\"\n",
    "r_m = 1.0\n",
    "r_p = 1.0\n",
    "k_on = 0.05\n",
    "k_off = 0.10\n",
    "gamma_m = 0.23\n",
    "gamma_p = 0.23\n",
    "\n",
    "# Hyperparameters\n",
    "num_simulations=100\n",
    "a_inv=200.0\n",
    "b_inv=20.0\n",
    "c=20.0\n",
    "sim_time=5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c64115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6609668])\n"
     ]
    }
   ],
   "source": [
    "# run sims\n",
    "mean_final_state, variance =  gillespie_simulation(r_m, r_p, k_on, k_off, num_simulations, sim_time, a_inv, b_inv, c)\n",
    "\n",
    "# store output\n",
    "ground_truth = {'r_m': r_m, 'r_p': r_p, 'k_on': k_on, 'k_off': k_off, 'mean_mrna': mean_final_state, 'variance_mrna': variance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ba484d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2416090/3400642974.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_mean = torch.tensor(ground_truth['mean_mrna'])\n",
      "/tmp/ipykernel_2416090/3400642974.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_std = torch.sqrt(torch.tensor(ground_truth['variance_mrna']))\n",
      "  3%|██████                                                                                                                                                                                | 1/30 [00:01<00:42,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████████████▏                                                                                                                                                                         | 2/30 [00:03<00:45,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████████████▏                                                                                                                                                                   | 3/30 [00:05<00:47,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7043)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████████████████████████▎                                                                                                                                                             | 4/30 [00:07<00:48,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████████████████████▎                                                                                                                                                       | 5/30 [00:09<00:48,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5390)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████████████████████████▍                                                                                                                                                 | 6/30 [00:11<00:45,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4786)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████████████████████████████▍                                                                                                                                           | 7/30 [00:12<00:43,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████████████████████████████████▌                                                                                                                                     | 8/30 [00:14<00:39,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3361)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████████████████████████████████████▌                                                                                                                               | 9/30 [00:16<00:36,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████████████████████████████████████▎                                                                                                                        | 10/30 [00:18<00:40,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████████████████████████████████████████▎                                                                                                                  | 11/30 [00:20<00:36,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1147)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████████████████████████████████████████████▍                                                                                                            | 12/30 [00:22<00:33,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████████████████████████████████████████████████▍                                                                                                      | 13/30 [00:23<00:29,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9703)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████████████████████████████████████████████████████████▍                                                                                                | 14/30 [00:25<00:26,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9156)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 15/30 [00:26<00:24,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8807)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                    | 16/30 [00:28<00:22,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                              | 17/30 [00:29<00:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                        | 18/30 [00:31<00:18,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8065)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                  | 19/30 [00:32<00:17,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                            | 20/30 [00:34<00:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7655)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 21/30 [00:36<00:15,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7635)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                | 22/30 [00:37<00:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7834)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                          | 23/30 [00:39<00:11,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8176)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                    | 24/30 [00:41<00:09,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                              | 25/30 [00:43<00:08,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 26/30 [00:45<00:07,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9062)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                  | 27/30 [00:47<00:05,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9351)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 28/30 [00:49<00:03,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉      | 29/30 [00:51<00:02,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:54<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0378)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility \n",
    "torch.manual_seed(40)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_simulations = 100\n",
    "num_iterations = 30\n",
    "\n",
    "# Initialize parameters\n",
    "r_m = torch.nn.Parameter(torch.tensor(2.0))\n",
    "r_p =  torch.nn.Parameter(torch.tensor(0.5))\n",
    "k_on =  torch.nn.Parameter(torch.tensor(0.01))\n",
    "k_off =  torch.nn.Parameter(torch.tensor(0.2))\n",
    "\n",
    "# Define the Adam optimizer\n",
    "optimizer = torch.optim.Adam([r_m, r_p, k_on, k_off], lr=0.1)\n",
    "\n",
    "# Set target mean and standard deviation\n",
    "target_mean = torch.tensor(ground_truth['mean_mrna'])\n",
    "target_std = torch.sqrt(torch.tensor(ground_truth['variance_mrna']))\n",
    "\n",
    "# Loop through each iteration\n",
    "for iteration in tqdm(range(num_iterations)):\n",
    "\n",
    "    # Forward differentiable Gillespie simulation\n",
    "    mean_final_state, variance =  gillespie_simulation(r_m, r_p, k_on, k_off, num_simulations, sim_time, a_inv, b_inv, c)\n",
    "\n",
    "    # Compute the loss for the current iteration\n",
    "    loss = loss_function(mean_final_state, variance, target_mean, target_std)\n",
    "\n",
    "    # Zero the gradients to prepare for backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient clipping\n",
    "    torch.nn.utils.clip_grad_norm_([r_m, r_p, k_on, k_off], max_norm=0.2)\n",
    "\n",
    "    # Update the parameters using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Clamp the parameter values to certain bounds\n",
    "    r_m.data = torch.clamp(r_m.data, min=0.01, max=100.0)\n",
    "    r_p.data = torch.clamp(r_p.data, min=0.01, max=100.0)\n",
    "    k_on.data = torch.clamp(k_on.data, min=0.001, max=100.0)\n",
    "    k_off.data = torch.clamp(k_off.data, min=0.001, max=100.0)\n",
    "    \n",
    "    print(r_m.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7398d1a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0378)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_m.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "178703e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0903)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b6ad33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0010)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_on.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ce9528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3731)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_off.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd7b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ome_zarr)",
   "language": "python",
   "name": "ome_zarr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
